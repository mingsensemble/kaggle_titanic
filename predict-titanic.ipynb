{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Titanic Casualties\n",
    "This is my first attempt on Kaggle competition. The goal is to achieve accuracy of 80% on the testing sample.  My strategy is to understand the data and then experiment with different common methodologies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "The first step at data exploration is to identify the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "l = train.shape[0]\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "test['Survived'] = -1 # code unknown survived = -1\n",
    "\n",
    "all_data = pd.concat([train, test], axis = 0, ignore_index = True, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0   NaN        S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                           Allen, Mr. William Henry      0            5   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived            Ticket  \n",
       "0       3    male      1         0         A/5 21171  \n",
       "1       1  female      1         1          PC 17599  \n",
       "2       3  female      0         1  STON/O2. 3101282  \n",
       "3       1  female      1         1            113803  \n",
       "4       3    male      0         0            373450  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four fields in the whole sampels of both training and testing samples have missing values.  I decide to discretize **Age** variable and impute the missing **Fare**.  **Cabin** and **Embarked** are categorical; therefore, an Unknown category is assigned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age             263\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "Fare              1\n",
       "Name              0\n",
       "Parch             0\n",
       "PassengerId       0\n",
       "Pclass            0\n",
       "Sex               0\n",
       "SibSp             0\n",
       "Survived          0\n",
       "Ticket            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket\n",
    "**Ticket** is one of the most interesting field to investigate.  Firstly, there seems to be no unified pattern in the ticket number.  However, a quick data summary reveals that many passengers have the same ticket number.  Fares seem to be calculated by the total fares of the same ticket number.  It may be more informative to use **Fare per Ticket** as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>16.0</td>\n",
       "      <td>B79</td>\n",
       "      <td>S</td>\n",
       "      <td>86.5000</td>\n",
       "      <td>Maioni, Miss. Roberta</td>\n",
       "      <td>0</td>\n",
       "      <td>505</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>30.0</td>\n",
       "      <td>B77</td>\n",
       "      <td>S</td>\n",
       "      <td>86.5000</td>\n",
       "      <td>Cherry, Miss. Gladys</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>33.0</td>\n",
       "      <td>B77</td>\n",
       "      <td>S</td>\n",
       "      <td>86.5000</td>\n",
       "      <td>Rothes, the Countess. of (Lucy Noel Martha Dye...</td>\n",
       "      <td>0</td>\n",
       "      <td>760</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>18.0</td>\n",
       "      <td>E68</td>\n",
       "      <td>S</td>\n",
       "      <td>79.6500</td>\n",
       "      <td>Taussig, Miss. Ruth</td>\n",
       "      <td>2</td>\n",
       "      <td>586</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>52.0</td>\n",
       "      <td>E67</td>\n",
       "      <td>S</td>\n",
       "      <td>79.6500</td>\n",
       "      <td>Taussig, Mr. Emil</td>\n",
       "      <td>1</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>39.0</td>\n",
       "      <td>E67</td>\n",
       "      <td>S</td>\n",
       "      <td>79.6500</td>\n",
       "      <td>Taussig, Mrs. Emil (Tillie Mandelbaum)</td>\n",
       "      <td>1</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>47.0</td>\n",
       "      <td>C110</td>\n",
       "      <td>S</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>Porter, Mr. Walter Chamberlain</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A14</td>\n",
       "      <td>S</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>Clifford, Mr. George Quincy</td>\n",
       "      <td>0</td>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>30.0</td>\n",
       "      <td>C106</td>\n",
       "      <td>S</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Maguire, Mr. John Edward</td>\n",
       "      <td>0</td>\n",
       "      <td>1227</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>110469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>42.0</td>\n",
       "      <td>D22</td>\n",
       "      <td>S</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>Borebank, Mr. John James</td>\n",
       "      <td>0</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>110489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>28.0</td>\n",
       "      <td>C52</td>\n",
       "      <td>S</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>Bjornstrom-Steffansson, Mr. Mauritz Hakan</td>\n",
       "      <td>0</td>\n",
       "      <td>431</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>60.0</td>\n",
       "      <td>D37</td>\n",
       "      <td>C</td>\n",
       "      <td>75.2500</td>\n",
       "      <td>Warren, Mrs. Frank Manley (Anna Sophia Atkinson)</td>\n",
       "      <td>0</td>\n",
       "      <td>367</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>64.0</td>\n",
       "      <td>D37</td>\n",
       "      <td>C</td>\n",
       "      <td>75.2500</td>\n",
       "      <td>Warren, Mr. Frank Manley</td>\n",
       "      <td>0</td>\n",
       "      <td>1128</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>110813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Salomon, Mr. Abraham L</td>\n",
       "      <td>0</td>\n",
       "      <td>1083</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>111163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>61.0</td>\n",
       "      <td>B19</td>\n",
       "      <td>S</td>\n",
       "      <td>33.5000</td>\n",
       "      <td>Van der hoef, Mr. Wyckoff</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>47.0</td>\n",
       "      <td>E63</td>\n",
       "      <td>S</td>\n",
       "      <td>38.5000</td>\n",
       "      <td>Gee, Mr. Arthur H</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>16.0</td>\n",
       "      <td>B18</td>\n",
       "      <td>C</td>\n",
       "      <td>57.9792</td>\n",
       "      <td>Hippach, Miss. Jean Gertrude</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>44.0</td>\n",
       "      <td>B18</td>\n",
       "      <td>C</td>\n",
       "      <td>57.9792</td>\n",
       "      <td>Hippach, Mrs. Louis Albert (Ida Sophia Fischer)</td>\n",
       "      <td>1</td>\n",
       "      <td>524</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.0</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>0</td>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>Homer, Mr. Harry (\"Mr E Haven\")</td>\n",
       "      <td>0</td>\n",
       "      <td>605</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age Cabin Embarked     Fare  \\\n",
       "504   16.0   B79        S  86.5000   \n",
       "257   30.0   B77        S  86.5000   \n",
       "759   33.0   B77        S  86.5000   \n",
       "585   18.0   E68        S  79.6500   \n",
       "262   52.0   E67        S  79.6500   \n",
       "558   39.0   E67        S  79.6500   \n",
       "110   47.0  C110        S  52.0000   \n",
       "475    NaN   A14        S  52.0000   \n",
       "1226  30.0  C106        S  26.0000   \n",
       "1049  42.0   D22        S  26.5500   \n",
       "430   28.0   C52        S  26.5500   \n",
       "366   60.0   D37        C  75.2500   \n",
       "1127  64.0   D37        C  75.2500   \n",
       "1082   NaN   NaN        S  26.0000   \n",
       "170   61.0   B19        S  33.5000   \n",
       "462   47.0   E63        S  38.5000   \n",
       "329   16.0   B18        C  57.9792   \n",
       "523   44.0   B18        C  57.9792   \n",
       "889   26.0  C148        C  30.0000   \n",
       "604   35.0   NaN        C  26.5500   \n",
       "\n",
       "                                                   Name  Parch  PassengerId  \\\n",
       "504                               Maioni, Miss. Roberta      0          505   \n",
       "257                                Cherry, Miss. Gladys      0          258   \n",
       "759   Rothes, the Countess. of (Lucy Noel Martha Dye...      0          760   \n",
       "585                                 Taussig, Miss. Ruth      2          586   \n",
       "262                                   Taussig, Mr. Emil      1          263   \n",
       "558              Taussig, Mrs. Emil (Tillie Mandelbaum)      1          559   \n",
       "110                      Porter, Mr. Walter Chamberlain      0          111   \n",
       "475                         Clifford, Mr. George Quincy      0          476   \n",
       "1226                           Maguire, Mr. John Edward      0         1227   \n",
       "1049                           Borebank, Mr. John James      0         1050   \n",
       "430           Bjornstrom-Steffansson, Mr. Mauritz Hakan      0          431   \n",
       "366    Warren, Mrs. Frank Manley (Anna Sophia Atkinson)      0          367   \n",
       "1127                           Warren, Mr. Frank Manley      0         1128   \n",
       "1082                             Salomon, Mr. Abraham L      0         1083   \n",
       "170                           Van der hoef, Mr. Wyckoff      0          171   \n",
       "462                                   Gee, Mr. Arthur H      0          463   \n",
       "329                        Hippach, Miss. Jean Gertrude      1          330   \n",
       "523     Hippach, Mrs. Louis Albert (Ida Sophia Fischer)      1          524   \n",
       "889                               Behr, Mr. Karl Howell      0          890   \n",
       "604                     Homer, Mr. Harry (\"Mr E Haven\")      0          605   \n",
       "\n",
       "      Pclass     Sex  SibSp  Survived  Ticket  \n",
       "504        1  female      0         1  110152  \n",
       "257        1  female      0         1  110152  \n",
       "759        1  female      0         1  110152  \n",
       "585        1  female      0         1  110413  \n",
       "262        1    male      1         0  110413  \n",
       "558        1  female      1         1  110413  \n",
       "110        1    male      0         0  110465  \n",
       "475        1    male      0         0  110465  \n",
       "1226       1    male      0        -1  110469  \n",
       "1049       1    male      0        -1  110489  \n",
       "430        1    male      0         1  110564  \n",
       "366        1  female      1         1  110813  \n",
       "1127       1    male      1        -1  110813  \n",
       "1082       1    male      0        -1  111163  \n",
       "170        1    male      0         0  111240  \n",
       "462        1    male      0         0  111320  \n",
       "329        1  female      0         1  111361  \n",
       "523        1  female      0         1  111361  \n",
       "889        1    male      0         1  111369  \n",
       "604        1    male      0         1  111426  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.sort_values(['Ticket']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticket\n",
       "110152               3\n",
       "110413               3\n",
       "110465               2\n",
       "110469               1\n",
       "110489               1\n",
       "110564               1\n",
       "110813               2\n",
       "111163               1\n",
       "111240               1\n",
       "111320               1\n",
       "111361               2\n",
       "111369               1\n",
       "111426               1\n",
       "111427               1\n",
       "111428               1\n",
       "112050               1\n",
       "112051               1\n",
       "112052               1\n",
       "112053               1\n",
       "112058               2\n",
       "112059               1\n",
       "112277               1\n",
       "112377               1\n",
       "112378               2\n",
       "112379               1\n",
       "112901               1\n",
       "113028               1\n",
       "113038               1\n",
       "113043               1\n",
       "113044               1\n",
       "                    ..\n",
       "STON/O 2. 3101273    1\n",
       "STON/O 2. 3101274    1\n",
       "STON/O 2. 3101275    1\n",
       "STON/O 2. 3101280    1\n",
       "STON/O 2. 3101285    1\n",
       "STON/O 2. 3101286    1\n",
       "STON/O 2. 3101288    1\n",
       "STON/O 2. 3101289    1\n",
       "STON/O 2. 3101291    1\n",
       "STON/O 2. 3101292    1\n",
       "STON/O 2. 3101293    1\n",
       "STON/O 2. 3101294    1\n",
       "STON/O2. 3101270     1\n",
       "STON/O2. 3101271     1\n",
       "STON/O2. 3101279     2\n",
       "STON/O2. 3101282     1\n",
       "STON/O2. 3101283     1\n",
       "STON/O2. 3101290     1\n",
       "STON/OQ. 369943      1\n",
       "SW/PP 751            1\n",
       "W./C. 14258          1\n",
       "W./C. 14260          1\n",
       "W./C. 14263          1\n",
       "W./C. 14266          1\n",
       "W./C. 6607           4\n",
       "W./C. 6608           5\n",
       "W./C. 6609           1\n",
       "W.E.P. 5734          2\n",
       "W/C 14208            1\n",
       "WE/P 5735            2\n",
       "Name: ticket_counts, Length: 929, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticket_tab = all_data.groupby(['Ticket']).size()\n",
    "ticket_tab.rename('ticket_counts', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.join(ticket_tab, on = 'Ticket').sort_values(['Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['fare_per_ticket'] = all_data['Fare']/all_data['ticket_counts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cabin\n",
    "Assuming **Cabin** starting with the same letter should be close to each other, I define a new feature **deck** to capture this assumption in the data.  **deck** is defined as the first letter of **Cabin**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[all_data['Cabin'].isna(), 'Cabin'] = 'Unknown'\n",
    "all_data['deck'] = [x[0] if x != 'Unknown' else 'Unknown' for x in all_data['Cabin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJLUMBUlSy1CQJLUMBUlS6/8BjRsh1zFdMaIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_df = all_data.loc[all_data['Survived'] != -1, ['deck', 'Survived']].groupby(['deck']).mean()\n",
    "from matplotlib import pyplot as plt\n",
    "plt.bar(plt_df.index, plt_df['Survived'])\n",
    "plt.xlabel('Deck')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title\n",
    "**Name** is another field I have not used yet.  I extract the title in the name and then combine different titles into **Mr.**, **Mrs.**, **Ms.**, and **Master.**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "for j in range(len(all_data['Name'])):\n",
    "    title.append([w for w in all_data['Name'][j].split() if w.endswith('.')][0])\n",
    "all_data['title'] = title\n",
    "\n",
    "# group titles\n",
    "mapping = {'Mlle.': 'Miss.', 'Major.': 'Mr.', 'Col.': 'Mr.', 'Sir.': 'Mr.',\n",
    "           'Don.': 'Mr.', 'Mme.': 'Miss.', 'Jonkheer.': 'Mr.', 'Lady.': 'Mrs.',\n",
    "           'Capt.': 'Mr.', 'Countess.': 'Mrs.', 'Ms.': 'Miss.', 'Dona.': 'Mrs.', 'Rev.': 'Mr.',}\n",
    "all_data.replace({'title': mapping}, inplace = True)\n",
    "# Dr. is ambiguous in gender\n",
    "all_data.loc[[x == \"Dr.\" and y == \"female\" for x, y in zip(all_data['title'], all_data['Sex'])], \"title\"] = \"Mrs.\"\n",
    "all_data.loc[[x == \"Dr.\" and y == \"male\" for x, y in zip(all_data['title'], all_data['Sex'])], \"title\"] = \"Mr.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_df = all_data.loc[all_data['Survived'] != -1, ['title', 'Survived']].groupby('title').mean()\n",
    "from matplotlib import pyplot as plt\n",
    "plt.bar(plt_df.index, plt_df['Survived'])\n",
    "plt.xlabel('Title')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age\n",
    "Two strategies can be employed to deal with missing **Age**.  We can impute missing ages and treat **Age** as a numerical feature.  Or we can impute any number and discretize **Age** so that the imputed number means missing.  I adopt the second strategy in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing age with -99\n",
    "all_data.loc[all_data['Age'].isna(), 'Age'] = -99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group\n",
       "-99    263\n",
       " 1      56\n",
       " 2      30\n",
       " 3      29\n",
       " 4     133\n",
       " 5     195\n",
       " 6     166\n",
       " 7     115\n",
       " 8      95\n",
       " 9      72\n",
       " 10     60\n",
       " 11     36\n",
       " 12     26\n",
       " 13     23\n",
       " 14      4\n",
       " 15      4\n",
       " 16      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "all_data['age_group'] = [math.ceil(x/5) if x != -99 else -99 for x in all_data['Age']]\n",
    "all_data.groupby(['age_group']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_data = all_data[all_data['Survived'] != -1]\n",
    "age_surv = plt_data.loc[plt_data['Survived'] == 1, 'Age']\n",
    "age_nosurv = plt_data.loc[plt_data['Survived'] == 0, 'Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following graphic compares the survival rates for different ages.  Children seems to have a higher survival rate while older people most likely did not make it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(age_surv, bins = int(80/1), color = 'r', label = 'Survived', alpha = 0.5)\n",
    "plt.hist(age_nosurv, bins = int(80/1), color = 'b', label = 'Not Survived', alpha =0.5)\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[all_data['Embarked'].isna(), 'Embarked'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fare\n",
    "One missing fare in the testing dataset. I impute it based on its class and where he boarded the ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>ticket_counts</th>\n",
       "      <th>fare_per_ticket</th>\n",
       "      <th>deck</th>\n",
       "      <th>title</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storey, Mr. Thomas</td>\n",
       "      <td>0</td>\n",
       "      <td>1044</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3701</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age    Cabin Embarked  Fare                Name  Parch  PassengerId  \\\n",
       "1043  60.5  Unknown        S   NaN  Storey, Mr. Thomas      0         1044   \n",
       "\n",
       "      Pclass   Sex  SibSp  Survived Ticket  ticket_counts  fare_per_ticket  \\\n",
       "1043       3  male      0        -1   3701              1              NaN   \n",
       "\n",
       "         deck title  age_group  \n",
       "1043  Unknown   Mr.         13  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.loc[all_data['Fare'].isna(), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the median fare per ticket of people embarking from S and in Pclass 3 to impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_tab = all_data[['Pclass', 'Embarked', 'fare_per_ticket']].groupby(['Pclass', 'Embarked']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[all_data['Fare'].isna(), 'Fare'] = fare_tab['fare_per_ticket'][3]['S']\n",
    "all_data.loc[all_data['fare_per_ticket'].isna(), 'fare_per_ticket'] = fare_tab['fare_per_ticket'][3]['S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Family Size\n",
    "The difference between family size and the ticket counts can be used to infer whether a nanny or a servant traveled with the family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_size</th>\n",
       "      <th>ticket_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      family_size  ticket_counts\n",
       "504             1              3\n",
       "257             1              3\n",
       "759             1              3\n",
       "585             3              3\n",
       "262             3              3\n",
       "558             3              3\n",
       "110             1              2\n",
       "475             1              2\n",
       "1226            1              1\n",
       "1049            1              1\n",
       "430             1              1\n",
       "366             2              2\n",
       "1127            2              2\n",
       "1082            1              1\n",
       "170             1              1\n",
       "462             1              1\n",
       "329             2              2\n",
       "523             2              2\n",
       "889             1              1\n",
       "604             1              1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['family_size'] = all_data['Parch'] + all_data['SibSp'] + 1\n",
    "all_data[['family_size', 'ticket_counts']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['companions'] = all_data['ticket_counts'] - all_data['family_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ix = np.where(all_data['Survived'] == -1)[0]\n",
    "train_ix = np.where(all_data['Survived'] != -1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Cabin', 'Embarked', 'Fare', 'Name', 'Parch', 'PassengerId',\n",
      "       'Pclass', 'Sex', 'SibSp', 'Survived', 'Ticket', 'ticket_counts',\n",
      "       'fare_per_ticket', 'deck', 'title', 'age_group', 'family_size',\n",
      "       'companions'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(all_data.columns)\n",
    "var_cat = ['Embarked',  'Pclass', 'Sex', 'deck', 'title', 'age_group']\n",
    "var_num = ['Parch', 'SibSp', 'fare_per_ticket', 'family_size', 'companions', 'ticket_counts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "def process_data(data, var_num, var_cat):\n",
    "    lst = []\n",
    "    for i in range(len(var_cat)):\n",
    "        encoder = LabelEncoder()\n",
    "        encoded = encoder.fit_transform(data[var_cat[i]].values)\n",
    "        encoder = OneHotEncoder()\n",
    "        lst.append(encoder.fit_transform(encoded.reshape(-1, 1)).toarray())\n",
    "    out_cat = np.concatenate(lst, axis = 1)\n",
    "    scaler = StandardScaler()\n",
    "    out_num = scaler.fit_transform(data[var_num].values)\n",
    "    out = np.concatenate([out_num, out_cat], axis = 1)\n",
    "    targets = data['Survived'].values\n",
    "    return out, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 9, random_state = 42)\n",
    "x_all, y_all = process_data(all_data, var_num, var_cat)\n",
    "x = x_all[train_ix]\n",
    "y = y_all[train_ix]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 5 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=9, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'min_impurity_decrease': [0, 0.001, 0.005, 0.01, 0.05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param = {'min_impurity_decrease': [0, 0.001, 0.005, 0.01, 0.05]}\n",
    "dtc = DecisionTreeClassifier()\n",
    "clf = GridSearchCV(dtc, param, cv = kf, verbose = 1, scoring = 'accuracy')\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_impurity_decrease': 0.005}\n",
      "0.8204264870931538\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.03021405, 0.03452053, 0.02442377,\n",
       "       0.05513946, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.15127986, 0.60402135, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.06843938, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03196159,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(min_impurity_decrease = 0.005)\n",
    "dtc.fit(x, y)\n",
    "dtc.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 36 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 324 out of 324 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=9, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [1, 10, 100, 1000], 'kernel': ['linear']}, {'C': [1, 10, 100, 1000], 'gamma': [0.1, 0.01, 0.001], 'kernel': ['rbf']}, {'C': [1, 10, 100, 1000], 'degree': [2, 3, 4, 5, 6], 'kernel': ['poly']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "param = [\n",
    "    {'C': [1, 10, 100, 1000], 'kernel':['linear']},\n",
    "    {'C': [1, 10, 100, 1000], 'gamma': [0.1, 0.01, 0.001], 'kernel':['rbf']},\n",
    "    {'C': [1, 10, 100, 1000], 'degree': [2, 3, 4, 5, 6], 'kernel':['poly']}\n",
    "]\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, param, cv = kf, verbose = 1, scoring = 'accuracy')\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8148148148148148\n",
      "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71076309,  0.48128777,  0.87089402, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.4449995 , -0.47908676,  1.38393622, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.4449995 , -0.47908676,  1.75303133, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.4449995 , -0.47908676, -0.50398526, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.4449995 , -0.47908676, -0.31390128, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.4449995 , -0.47908676, -0.31390128, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(C = 1000, gamma = 0.001, kernel ='rbf')\n",
    "svc.fit(x, y)\n",
    "svc.support_vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 4 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=9, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1, 10, 100, 1000]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='accuracy',\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "param = {'C': [1, 10, 100, 1000]}\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, param, cv = kf, verbose = 1, scoring = 'accuracy')\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7991021324354658\n",
      "{'C': 10}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.84798303e-03, -2.54908400e-01,  2.97756322e-01,\n",
       "        -1.71958610e-01,  1.28934432e-01, -7.48868016e-02,\n",
       "         8.85927320e-02, -2.24141365e-03, -4.78796422e-01,\n",
       "         5.70786171e-01,  3.72087155e-01,  3.89988574e-01,\n",
       "        -5.83734661e-01,  1.52369355e+00, -1.34535248e+00,\n",
       "         1.56400740e-01,  5.03932889e-01,  4.17976998e-02,\n",
       "         9.77351174e-01,  1.50459693e+00,  4.68934017e-01,\n",
       "        -1.52841225e+00, -1.55703270e+00, -3.89227431e-01,\n",
       "         5.31026200e-01, -5.40661850e-02,  5.41623843e-02,\n",
       "        -3.52781332e-01, -1.08408591e-02,  2.87292465e+00,\n",
       "         7.16339711e-01,  8.97679788e-01,  2.06437766e-01,\n",
       "        -1.03799400e-01,  3.48743208e-01,  6.64289357e-01,\n",
       "        -1.49543470e-01, -9.14442451e-02, -5.64086630e-01,\n",
       "        -4.86925974e-01, -1.08393904e+00, -9.69122090e-01,\n",
       "        -1.86443492e+00, -2.12825462e+00,  1.92431784e+00]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 10)\n",
    "lr.fit(x, y)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "dtc = DecisionTreeClassifier(min_impurity_decrease = 0.005)\n",
    "svc = SVC(C = 1000, gamma = 0.001, kernel = 'rbf')\n",
    "lr = LogisticRegression(C = 10)\n",
    "eclf = VotingClassifier(estimators = [('dtc', dtc), ('svc', svc), ('lr', lr)], voting = 'hard')\n",
    "cv_res = []\n",
    "for tr_ix, te_ix in kf.split(x):\n",
    "    x_train, x_test, y_train, y_test = x[tr_ix], x[te_ix], y[tr_ix], y[te_ix]\n",
    "    dtc.fit(x_train, y_train)\n",
    "    svc.fit(x_train, y_train)\n",
    "    lr.fit(x_train, y_train)\n",
    "    cv_res.append(accuracy_score(y_test, [int(y1 + y2 + y3 >= 2) for y1, y2, y3 in zip(dtc.predict(x_test), svc.predict(x_test), lr.predict(x_test))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125701459034792"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 120 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1080 out of 1080 | elapsed: 10.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=9, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [10, 100, 500, 1000], 'max_depth': [1, 2, None], 'max_features': [None, 'sqrt'], 'min_impurity_decrease': [0, 0.001, 0.005, 0.01, 0.05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param = {\n",
    "    'n_estimators': [10, 100, 500, 1000,],\n",
    "    'max_depth': [1, 2, None],\n",
    "    'max_features': [None, 'sqrt'], \n",
    "    'min_impurity_decrease': [0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "rfc = RandomForestClassifier()\n",
    "clf = GridSearchCV(rfc, param, cv = kf, verbose = 1, scoring = 'accuracy')\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8271604938271605\n",
      "{'max_depth': None, 'max_features': None, 'min_impurity_decrease': 0.005, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 216 candidates, totalling 1944 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1944 out of 1944 | elapsed: 15.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=9, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [10, 100, 500], 'max_depth': [1, 2, None], 'max_features': [None, 'sqrt'], 'min_impurity_decrease': [0, 0.001, 0.005, 0.01], 'learning_rate': [0.1, 0.01, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "param = {\n",
    "    'n_estimators': [10, 100, 500,],\n",
    "    'max_depth': [1, 2, None],\n",
    "    'max_features': [None, 'sqrt'], \n",
    "    'min_impurity_decrease': [0, 0.001, 0.005, 0.01, ], \n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "gbc = GradientBoostingClassifier()\n",
    "clf = GridSearchCV(gbc, param, cv = kf, verbose = 1, scoring = 'accuracy')\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8148148148148148\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'max_features': 'sqrt', 'min_impurity_decrease': 0, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 596 samples, validate on 295 samples\n",
      "Epoch 1/40\n",
      "596/596 [==============================] - 1s 2ms/step - loss: 0.6489 - acc: 0.5772 - val_loss: 0.6007 - val_acc: 0.6644\n",
      "Epoch 2/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.5303 - acc: 0.7232 - val_loss: 0.5762 - val_acc: 0.7186\n",
      "Epoch 3/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4862 - acc: 0.7785 - val_loss: 0.5328 - val_acc: 0.7627\n",
      "Epoch 4/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4634 - acc: 0.7785 - val_loss: 0.5029 - val_acc: 0.7831\n",
      "Epoch 5/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4356 - acc: 0.8054 - val_loss: 0.5302 - val_acc: 0.7831\n",
      "Epoch 6/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4485 - acc: 0.8020 - val_loss: 0.5012 - val_acc: 0.8102\n",
      "Epoch 7/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4293 - acc: 0.8188 - val_loss: 0.4977 - val_acc: 0.8169\n",
      "Epoch 8/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4350 - acc: 0.8154 - val_loss: 0.5108 - val_acc: 0.8203\n",
      "Epoch 9/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4260 - acc: 0.8188 - val_loss: 0.5111 - val_acc: 0.8136\n",
      "Epoch 10/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4276 - acc: 0.8289 - val_loss: 0.5024 - val_acc: 0.8271\n",
      "Epoch 11/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.3967 - acc: 0.8440 - val_loss: 0.5299 - val_acc: 0.7966\n",
      "Epoch 12/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4172 - acc: 0.8272 - val_loss: 0.4938 - val_acc: 0.8271\n",
      "Epoch 13/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4026 - acc: 0.8456 - val_loss: 0.5064 - val_acc: 0.8305\n",
      "Epoch 14/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4189 - acc: 0.8356 - val_loss: 0.4891 - val_acc: 0.8169\n",
      "Epoch 15/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4157 - acc: 0.8406 - val_loss: 0.5006 - val_acc: 0.8203\n",
      "Epoch 16/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4005 - acc: 0.8372 - val_loss: 0.4992 - val_acc: 0.8034\n",
      "Epoch 17/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.3959 - acc: 0.8456 - val_loss: 0.5153 - val_acc: 0.8000\n",
      "Epoch 18/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4336 - acc: 0.8305 - val_loss: 0.5058 - val_acc: 0.8169\n",
      "Epoch 19/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4359 - acc: 0.8289 - val_loss: 0.5035 - val_acc: 0.8203\n",
      "Epoch 20/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4168 - acc: 0.8440 - val_loss: 0.5165 - val_acc: 0.8237\n",
      "Epoch 21/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4069 - acc: 0.8507 - val_loss: 0.5414 - val_acc: 0.8068\n",
      "Epoch 22/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4191 - acc: 0.8456 - val_loss: 0.5399 - val_acc: 0.8068\n",
      "Epoch 23/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4075 - acc: 0.8456 - val_loss: 0.5433 - val_acc: 0.8237\n",
      "Epoch 24/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4229 - acc: 0.8490 - val_loss: 0.5281 - val_acc: 0.8203\n",
      "Epoch 25/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4125 - acc: 0.8507 - val_loss: 0.5483 - val_acc: 0.8203\n",
      "Epoch 26/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4083 - acc: 0.8658 - val_loss: 0.5718 - val_acc: 0.8237\n",
      "Epoch 27/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4112 - acc: 0.8557 - val_loss: 0.5661 - val_acc: 0.8102\n",
      "Epoch 28/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4043 - acc: 0.8456 - val_loss: 0.5554 - val_acc: 0.8203\n",
      "Epoch 29/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4177 - acc: 0.8507 - val_loss: 0.5493 - val_acc: 0.8305\n",
      "Epoch 30/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4030 - acc: 0.8523 - val_loss: 0.5621 - val_acc: 0.8102\n",
      "Epoch 31/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4210 - acc: 0.8540 - val_loss: 0.5257 - val_acc: 0.8203\n",
      "Epoch 32/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4152 - acc: 0.8507 - val_loss: 0.5587 - val_acc: 0.8237\n",
      "Epoch 33/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4318 - acc: 0.8473 - val_loss: 0.5416 - val_acc: 0.8305\n",
      "Epoch 34/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.3985 - acc: 0.8708 - val_loss: 0.5613 - val_acc: 0.8169\n",
      "Epoch 35/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4336 - acc: 0.8440 - val_loss: 0.5834 - val_acc: 0.8102\n",
      "Epoch 36/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4433 - acc: 0.8440 - val_loss: 0.5720 - val_acc: 0.8305\n",
      "Epoch 37/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.3862 - acc: 0.8691 - val_loss: 0.6390 - val_acc: 0.8203\n",
      "Epoch 38/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4528 - acc: 0.8540 - val_loss: 0.5840 - val_acc: 0.8237\n",
      "Epoch 39/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4194 - acc: 0.8523 - val_loss: 0.5795 - val_acc: 0.8271\n",
      "Epoch 40/40\n",
      "596/596 [==============================] - 1s 1ms/step - loss: 0.4209 - acc: 0.8658 - val_loss: 0.6132 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "\n",
    "from keras import models, layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation = 'relu', input_shape = (x.shape[1], )))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(16, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "res = model.fit(x, y, epochs = 40, batch_size = 1, validation_split = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = len(res.history['acc'])\n",
    "plt.plot(range(n_epochs), res.history['acc'], color = 'b', label = 'training')\n",
    "plt.plot(range(n_epochs), res.history['val_acc'], color = 'r', label = 'validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Predictions\n",
    "A key finding in this exercise is that tree-based algorithm performs better than its alternatives, such as neural network, logistic regression, or support vector machine.  So far the best performing algorithms are random forest and gradient boosting machine.\n",
    "### Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_all[test_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(min_impurity_decrease = 0.005)\n",
    "dtc.fit(x, y)\n",
    "dtc_pred = dtc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C = 1000, gamma = 0.001, kernel = 'rbf')\n",
    "svc.fit(x, y)\n",
    "svc_pred = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = 10)\n",
    "lr.fit(x, y)\n",
    "lr_pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_pred = [int(x + y + z >= 2) for x, y, z in zip(lr_pred, svc_pred, dtc_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    max_depth = None, \n",
    "    max_features = None, \n",
    "    min_impurity_decrease = 0.005, \n",
    "    n_estimators = 100\n",
    ")\n",
    "rfc.fit(x, y)\n",
    "rfc_pred = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(\n",
    "    max_depth = 2, \n",
    "    max_features = 'sqrt', \n",
    "    min_impurity_decrease = 0.005, \n",
    "    n_estimators = 100, \n",
    "    learning_rate = 0.1\n",
    ")\n",
    "gbc.fit(x, y)\n",
    "gbc_pred = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "891/891 [==============================] - 1s 1ms/step - loss: 0.6011 - acc: 0.6622\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 1s 893us/step - loss: 0.5006 - acc: 0.7654\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 1s 894us/step - loss: 0.4896 - acc: 0.7935\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 1s 890us/step - loss: 0.4684 - acc: 0.8025\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 1s 898us/step - loss: 0.4656 - acc: 0.8013\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 1s 890us/step - loss: 0.4517 - acc: 0.8114\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 1s 901us/step - loss: 0.4644 - acc: 0.8260\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 1s 893us/step - loss: 0.4570 - acc: 0.8159\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 1s 892us/step - loss: 0.4292 - acc: 0.8350\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 1s 893us/step - loss: 0.4330 - acc: 0.8350\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(42)\n",
    "\n",
    "nnc = models.Sequential()\n",
    "nnc.add(layers.Dense(16, activation = 'relu', input_shape = (x.shape[1], )))\n",
    "nnc.add(layers.Dropout(0.1))\n",
    "nnc.add(layers.Dense(16, activation = 'relu'))\n",
    "nnc.add(layers.Dropout(0.1))\n",
    "nnc.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "nnc.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "nnc.fit(x, y, epochs = 10, batch_size = 1)\n",
    "nnc_pred = [int(x > 0.5) for x in nnc.predict(x_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = gbc_pred\n",
    "PassengerId = all_data.iloc[test_ix]['PassengerId'].reset_index()\n",
    "Survived = pd.Series(yhat)\n",
    "\n",
    "out = pd.concat([PassengerId, Survived], axis = 1, ignore_index = True)\n",
    "out.columns = ['index', 'PassengerId', 'Survived']\n",
    "out.set_index('index', inplace = True)\n",
    "out.sort_values(['PassengerId']).to_csv('fin_pred.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
